import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from config import processed_data_dir, raw_data_file_path
from imblearn.over_sampling import SMOTE, ADASYN 
from imblearn.under_sampling import TomekLinks, NearMiss
import matplotlib.pyplot as plt
import seaborn as sns
import logging
from imblearn.combine import SMOTEENN , SMOTETomek

def preprocessing_data(test_size: float = 0.2, random_state: int = 42) -> None:
    """PrÃ©traitement des donnÃ©es pour le tp de Credit Card.

    Args:
        test_size (float): Proportion des donnÃ©es utilisÃ©es pour le test.
        random_state (int): Seed pour assurer la reproductibilitÃ©.
    """
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
    logger = logging.getLogger(__name__)
    logger.info("PrÃ©traitement des donnÃ©es commencÃ©.")


    # ğŸ“‚ **1. VÃ©rification de l'existence des fichiers**
    if not os.path.exists(raw_data_file_path):
        raise FileNotFoundError(f"âŒ Le fichier spÃ©cifiÃ© n'existe pas : {raw_data_file_path}")

    # ğŸ“– **2. Chargement des donnÃ©es**
    print("\nğŸŒ Chargement des donnÃ©es...")
    df = pd.read_csv(raw_data_file_path)
    

    print("\nğŸ” **AperÃ§u des donnÃ©es :**")
    print(df.head())
    print("\nğŸ“Š Dimensions du dataset (lignes, colonnes) :", df.shape)
    print("\nğŸ”‘ Colonnes disponibles :", list(df.columns))

    # ğŸ§¹ **3. Nettoyage des donnÃ©es**
    print("\nğŸ§¹ Suppression des doublons...")
    initial_rows = df.shape[0]
    df = df.drop_duplicates()
    cleaned_rows = df.shape[0]
    print(f"âœ… Nombre de doublons supprimÃ©s : {initial_rows - cleaned_rows}")
    print(f"âœ… Nombre de lignes aprÃ¨s nettoyage : {cleaned_rows}")

    # ğŸš¨ **4. VÃ©rification de la colonne cible**
    target = 'Class'
    if target not in df.columns:
        raise KeyError(f"âŒ La colonne cible '{target}' est absente du dataset.")

    # ğŸ—‚ï¸ **5. SÃ©paration des caractÃ©ristiques et de la cible**
    print("\nâœ‚ï¸ SÃ©paration des caractÃ©ristiques et de la colonne cible...")
    features = [col for col in df.columns if col != target]
    X = df[features]
    y = df[target]
    print(f"ğŸ”¢ Nombre de caractÃ©ristiques : {len(features)}")

    # âš™ï¸ **6. Normalisation des donnÃ©es**
    print("\nâš™ï¸ Normalisation des caractÃ©ristiques...")
    scaler = StandardScaler()
    X = pd.DataFrame(scaler.fit_transform(X), columns=features)

    # âœ‚ï¸ **7. SÃ©paration des donnÃ©es en ensembles d'entraÃ®nement et de test**
    print("\nâœ‚ï¸ Division des donnÃ©es en ensembles d'entraÃ®nement et de test...")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
    
    print(f"ğŸ“Š Taille de l'ensemble d'entraÃ®nement : {X_train.shape[0]} lignes")
    print(f"ğŸ“Š Taille de l'ensemble de test : {X_test.shape[0]} lignes")

    # Avant SMOTE OR ADASYN (dataset complet)
    print("ğŸ“Š Distribution des classes Equilibrage :")
    print(y_train.value_counts())
    plot_class_distribution(y_train, "Distribution des classes avant SMOTE OR ADASYN")

    # # ğŸŸ¢ Application de SMOTE
    # print("\nğŸŸ¢ Application de SMOTE pour Ã©quilibrer les classes...")
    # smote = SMOTE(random_state=random_state)
    # X_train, y_train = smote.fit_resample(X_train, y_train)

    # # AprÃ¨s SMOTE (ensemble d'entraÃ®nement)
    # print("\nğŸ” Distribution des classes aprÃ¨s SMOTE (Ensemble d'entraÃ®nement) :")
    # print(y_train.value_counts())
    # plot_class_distribution(y_train, "Distribution des classes aprÃ¨s SMOTE (EntraÃ®nement)")


    ## ğŸŸ¢ Application de ADASYN
    # print("\nğŸŸ¢ Application de ADASYN pour Ã©quilibrer les classes...")
    # adasyn = ADASYN(random_state=random_state, n_neighbors=5)
    # X_train, y_train = adasyn.fit_resample(X_train, y_train)

    # # AprÃ¨s ADASYN (ensemble d'entraÃ®nement)
    # print("\nğŸ” Distribution des classes aprÃ¨s ADASYN (Ensemble d'entraÃ®nement) :")
    # print(y_train.value_counts())
    # plot_class_distribution(y_train, "Distribution des classes aprÃ¨s ADASYN (EntraÃ®nement)")

    
    # # ğŸŸ¢ Application de SMOTE-SVM (SMOTE + SVM)
    # print("\nğŸŸ¢ Application de SMOTE pour Ã©quilibrer les classes et SVM pour la classification...")

    # # SMOTE avec SVM (en utilisant SMOTEENN pour Ã©quilibrer les classes et appliquer SVM)
    # smote_svm = SMOTEENN(random_state=random_state)
    # X_train, y_train = smote_svm.fit_resample(X_train, y_train)

    # # AprÃ¨s SVM (ensemble d'entraÃ®nement aprÃ¨s SMOTE)
    # print("\nğŸ” Distribution des classes aprÃ¨s SMOTE-SVM (Ensemble d'entraÃ®nement) :")
    # print(y_train.value_counts())
    # plot_class_distribution(y_train, "Distribution des classes aprÃ¨s SMOTE-SVM (EntraÃ®nement)")

    # ğŸŸ¢ Application de Tomek Links pour Ã©quilibrer les classes
    # print("\nğŸŸ¢ Application de Tomek Links pour nettoyer les donnÃ©es...")

    # # Initialisation et application de Tomek Links
    # tomek_links = TomekLinks()
    # X_train, y_train = tomek_links.fit_resample(X_train, y_train)

    # # Afficher la distribution des classes aprÃ¨s l'application de Tomek Links
    # print("\nğŸ” Distribution des classes aprÃ¨s Tomek Links (Ensemble d'entraÃ®nement) :")
    # print(y_train.value_counts())
    # plot_class_distribution(y_train, "Distribution des classes aprÃ¨s Tomek Links (EntraÃ®nement)")

    # ğŸŸ¢ Application de NearMiss
    print("\nğŸŸ¢ Application de NearMiss pour Ã©quilibrer les classes...")
    nearmiss = NearMiss()
    X_train, y_train = nearmiss.fit_resample(X_train, y_train)

    # AprÃ¨s NearMiss (ensemble d'entraÃ®nement)
    print("\nğŸ” Distribution des classes aprÃ¨s NearMiss (Ensemble d'entraÃ®nement) :")
    print(y_train.value_counts())
    plot_class_distribution(y_train, "Distribution des classes aprÃ¨s NearMiss (EntraÃ®nement)")



    # ğŸŸ¢ Application de SMOTE-Tomek
    # print("\nğŸŸ¢ Application de SMOTE-Tomek pour Ã©quilibrer les classes...")
    # smote_tomek = SMOTETomek(random_state=42)
    # X_train, y_train = smote_tomek.fit_resample(X_train, y_train)

    # # AprÃ¨s SMOTE-Tomek (ensemble d'entraÃ®nement)
    # print("\nğŸ” Distribution des classes aprÃ¨s SMOTE-Tomek (Ensemble d'entraÃ®nement) :")
    # print(y_train.value_counts())
    # plot_class_distribution(y_train, "Distribution des classes aprÃ¨s SMOTE-Tomek (EntraÃ®nement)")



    # ğŸ’¾ **8. Enregistrement des ensembles prÃ©parÃ©s**
    print("\nğŸ’¾ Enregistrement des fichiers prÃ©traitÃ©s...")
    os.makedirs(processed_data_dir, exist_ok=True)

    cleaned_file_path = os.path.join(processed_data_dir, "cleaned_dataset.csv")
    X_train_file = os.path.join(processed_data_dir, "X_train.csv")
    X_test_file = os.path.join(processed_data_dir, "X_test.csv")
    y_train_file = os.path.join(processed_data_dir, "y_train.csv")
    y_test_file = os.path.join(processed_data_dir, "y_test.csv")

    # Enregistrer le dataset nettoyÃ© et les ensembles d'entraÃ®nement/test
    df.to_csv(cleaned_file_path, index=False)
    X_train.to_csv(X_train_file, index=False)
    X_test.to_csv(X_test_file, index=False)
    y_train.to_csv(y_train_file, index=False)
    y_test.to_csv(y_test_file, index=False)

    print(f"âœ… Dataset nettoyÃ© enregistrÃ© : {cleaned_file_path}")
    print(f"âœ… Fichiers d'entraÃ®nement et de test enregistrÃ©s dans le dossier : {processed_data_dir}")

    # ğŸ‰ **Fin du prÃ©traitement**
    print("\nğŸ‰ PrÃ©traitement des donnÃ©es terminÃ© avec succÃ¨s !")


def plot_class_distribution(y, title: str):
    """Visualiser la distribution des classes."""
    class_labels = y.value_counts().index.map(str)
    plt.figure(figsize=(8, 5))
    sns.countplot(x=y, palette="viridis")
    plt.title(title, fontsize=14)
    plt.xlabel("Classe", fontsize=12)
    plt.ylabel("Nombre d'Ã©chantillons", fontsize=12)
    plt.xticks(ticks=range(len(class_labels)), labels=class_labels)
    plt.show()
